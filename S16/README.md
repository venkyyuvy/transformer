
# Translation using transformers

Optimizing the training time of transfomer

- One cycle policy
- Mixed precision training
- dynamic max_sequence length for batches
- cycle encoder and decoder layers
- dropping long translation datapoints
